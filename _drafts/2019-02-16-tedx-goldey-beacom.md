---
layout: post
title:  "A Flick of the Wrist: Defining the Next Generation of Human-Computer Interaction"
date:   2019-02-16
---

The following is a written version of a talk I did at TedX Goldey Beacom in January 2019. They filmed it, which you can watch eventually when they upload it 🙃

---

For years, we've been enchanted by the idea of magic. The thought that someone, with the wave of a wand, snap of a finger, or some special words, can completely change the world around them in an instant is an idea that has captured minds throughout history.

![a super magical hand image][magic]

> Any sufficiently advanced technology is indistinguishable from magic. - [Sir Arthur C. Clarke]

Right now, we live in a world where we manipulate the entirety of human knowledge on screens barely bigger than credit cards. I’d be willing to bet that everyone in this room has a device in their pocket that has more computing power than the technology we used to send people to space. And relative to the rest of human history, it’s all happened in the blink of an eye. It’s really difficult to overstate how far we’ve already come, even within my lifetime.

![2005][2005]

![2013][2013]

>[St. Peter’s Square in 2005 vs 2013 via NBC]

With the advent of extended reality, machine learning, and other emerging technologies, the way we work with computers and each other is going to drastically evolve over the next several years. We are increasingly able to not only perceive digital worlds in three dimensions but interact with and be seen by them in return. This is in essence, what the field of human-computer interaction is developing.

Today, I’m going to show you some HCI research projects that are pushing the boundaries of technology. I invite you to look ahead at how they will fundamentally change how we interact with computers, information, and each other.

But first, take a moment to dream with me. It’s 20XX, a Tuesday.

Imagine being a kid taking chemistry for the first time. Remember learning molecular geometry? The thing where atoms are arranged in various 3D shapes like tetrahedra and trigonal pyramidals? You had to draw them out on paper, using nothing but a pencil and ruler to visualize these abstract shapes that make up fundamental pieces of our world.

![molecular-geometry][molecular-geometry]

Or, maybe you were a bit luckier and did an activity where you arranged playdough and toothpicks like I did in high school. They are really sad and droopy. Instead of that, kids in 20XX play with holograms, building out octahedra and seesaws with their bare hands in space. They can manipulate atomic bonds intuitively, playing with digital representations that function as we understand things to at an atomic level.

![sad-playdough-1][sad-playdough-1]
![sad-playdough-2][sad-playdough-2]
![sad-playdough-3][sad-playdough-3]

Imagine you're out hiking and see a gorgeous landscape of mountains. Inspired by their beauty, you whip out your sketchbook, but you don't exactly have an entire collection of paints on your person. But that doesn't matter, as you draw thin wobbly lines, it transforms into a picturesque landscape painting right before your eyes.

![a stock photo of a human person drawing in the woods like a weirdo][drawing-stock-photo]

You get home from work and jump into a game that basically puts you into the matrix. As the lone hero, you stand alone in a hostile world. You’re swarmed by agents, and dodge bullets in slow-motion using your entire body.

![literally the matrix][matrix-dodge]

Now, you want to tell me that all of these sound crazy, requiring tech we don’t have, right? But it turns out, "20XX" is actually 2018. These are some of the things we did *last year*.

The chemistry application is [Project Pupil] at Carnegie Mellon.

![][project-pupil-chemistry]

The painting? An application by [Memo Akten].

![][learning-to-see-paint]

The slow-motion shooter? [Super Hot], which you can literally go to a VR arcade to play *right now*.

![][super-hot]

So, what are these things anyway? How are we doing this?

For the uninitiated, XR is used as an umbrella term to describe a continuum of combinations of real and virtual objects interacting in tandem. This includes technologies like virtual reality, where your entire environment is digital, augmented reality, where you overlay flat images onto the real world, and any dimension in between.

![][leap-mirrorworlds-concept]

Maybe you’ve played with primitive augmented reality systems, like [Pokemon Go], or are lucky enough to have tried virtual reality system sellers like [Beat Saber]. The one thing XR technologies have in common is they use computers to shape your perception. XR as a spectrum can put you in wholly new and different environments, or simply add information to the real world.

![][pokemon-go]
![][beat-saber]

Machine learning is essentially using particular algorithms to teach computers how to solve problems. It’s used in all sorts of applications, from [mastering Go] and [powering the brains of self-driving cars], to [generate cats from a handful of lines]. I drew that last one, he’s probably okay. There’s a lot of exciting work using machine learning to see the world through a computer’s eyes.

![][alphago]
![][waymo]
![][pix-2-cats-1]
![][pix-2-cats-2]
![My line drawing turned into a fuzzy monstrosity][pix-2-cats-derpy-cat]

We're able to take artificial intelligence and show it parts of the world. We can show them our bodies, our paintings, [how objects interact], see what they come up with, and use that to shape our perception. Machine learning is able to make sense of the vast amount of information in reality, while XR will help us see it more clearly. I feel like some of the most exciting developments have been through open source and publicly funded research projects.

![][machine-eye-memo]
![][everybody-dance-now]

[OpenPose] is a research project at Carnegie Mellon that uses machine learning to detect bodies in single images. It’s been used as the backbone for other work, including research projects that help [put your whole body in virtual reality], and help you, or at least, a video of you, do [intricate ballet dances].

![][openpose]
![][intel-realsense-ml-vr]

[Pix2Pix] is a project at Berkeley that uses neural networks to generate images based on training data. It’s been further remixed into applications that [turn your webcam feed into flowers], or turn photos of Wilmington’s skyline into gorgeous paintings that emulate Van Goh.

![Wilmington Deep Dreamed into a Starry Night][Wilmington]

> via [Deep Dream Generator]

[Project North Star] is an augmented reality headset that you can literally 3D print anywhere in the world. There’s a [community] growing around sourcing and building these headsets, and I think we’ll see some interesting applications as it becomes more accessible. These are all open source, so anyone can take their work and build on top of it to make all sorts of applications, which they have.

"They" includes me. I’m currently building my own North Star. Some of the parts I was able to 3D print back at the University of Delaware, others were sourced from community members that have cropped up around the project. This happened over UD’s summer scholars program, where I took 10 weeks to learn the basics of XR development. After the semester started, I turned that experience into an undergraduate research project focused on getting cross-disciplinary students together to develop XR applications.

![Me wearing my North Star][alina-north-star]

![My North Star build as of Summer 2018][north-star-build-summer-2018]

Just last week I went to [Reality Virtually], a hackathon at MIT’s Media lab. I got together with over 400 other developers, artists, designers, and coders to make XR applications. The one rule for all projects at the hackathon was that they had to be open source, so that anyone around the world could take what they made and create new and interesting applications. Together, we made just under 100 XR projects including tools for physical therapy and accessibility, but also games and interactive art. My team made a [VR escape room] in under 5 days, and my advisor [Dr. Barmaki’s physical therapy project] won “Best VR application”.

![Reality Virtually Squad Photo][reality-virtually-hci-squad]

![Reality Virtually Escape Room][escape-room]

In my mind, this technology really comes together in the concept of [Mirrorworlds]. Rather than ever leaving your physical space, this technology will help [transform it around you into another parallel dimension]. Chairs become mountains, walls become sunsets, and "the floor is lava" transforms from a simple kid's game into a visceral experience. You can interact with digital objects the same way as you would with physical, and interact with physical ones to an even greater effect. Your environment can show you how it works, as items show you how to use them. A guitar could teach you how to play itself, showing you where best to hold it to play particular chords. Or objects could change altogether, as tables turn into touch screens and pencils into wands.

![Mirrorworlds Leap Illustration][mirrorworlds-leap-illustration]

> It's time to shift the conversation from what an AR system should look like, to what an AR experience should feel like. - [David Holz]

The question is no longer "how can we make this work?" but rather "how should this feel?" We’re at point in history where what would have been considered "magic" is real. It’s here, and it’s now. And so, I leave you with this: What will you do with it?

Thank you.

------

I read many, many, *many* things to prep for this in order to create something mildly resembling a narrative for this talk. I did my best to save sources, here is the megalist, save for one that have been linked to directly:

[TedX Goldey Beacom]: https://www.ted.com/tedx/events/32155
[Project Pupil]: (https://www.etc.cmu.edu/blog/projects/pupil/)
[Super Hot]: (https://superhotgame.com/vr/)
[Memo Akten]: (https://www.memo.tv/portfolio/learning-to-see/)
[mastering Go]: (https://deepmind.com/research/alphago/)
[Project North Star]: (https://developer.leapmotion.com/northstar)
[powering the brains of self-driving cars]: (waymo.com)
[generate cats from a handful of lines]: (https://affinelayer.com/pixsrv/)
[Pokemon Go]: (pokemongo.com)
[Beat Saber]: (beatsaber.com)
[Mirrorworlds]: (http://blog.leapmotion.com/mirrorworlds/)
[Reality Virtually]: (https://realityvirtuallyhack.com/)
[VR escape room]: (https://devpost.com/software/virtual-escape-room-bj9lwv)
[Dr. Barmaki’s physical therapy project]: (https://devpost.com/software/move2improve)
[OpenPose]: (https://github.com/CMU-Perceptual-Computing-Lab/openpose)
[put your whole body in virtual reality]: (https://realsense.intel.com/deep-learning-for-vr-ar/)
[intricate ballet dances]: (https://carolineec.github.io/everybody_dance_now/)
[Pix2Pix]: (https://github.com/phillipi/pix2pix)
[turn your webcam feed into flowers]: (https://www.memo.tv/portfolio/learning-to-see/)
[Deep Dream Generator]: (https://deepdreamgenerator.com)
[community]: (https://discord.gg/fSEcBMe)
[Sir Arthur C. Clarke]: (https://en.wikipedia.org/wiki/Clarke's_three_laws)
[David Holz]: (http://blog.leapmotion.com/northstar/)
[how objects interact]: (https://www.youtube.com/watch?v=keffWSqi67w)
[transform it around you into another parallel dimension]: (https://cloud.google.com/maps-platform/gaming/)
[St. Peter’s Square in 2005 vs 2013 via NBC]: (http://photoblog.nbcnews.com/_news/2013/03/14/17312316-witnessing-papal-history-changes-with-digital-age)


[magic]: ../assets/img/magic-hand.jpg
[2005]: ../assets/img/st-peters-2005.jpg
[2013]: ../assets/img/st-peters-2013.jpg
[molecular-geometry]: ../assets/img/vsepr-geometries.png
[sad-playdough-1]: ../assets/img/sad-playdough-1.jpg
[sad-playdough-2]: ../assets/img/sad-playdough-2.jpg
[sad-playdough-3]: ../assets/img/sad-playdough-3.jpg
[drawing-stock-photo]: ../assets/img/drawing-stock-photo.png
[matrix-dodge]: ../assets/img/matrix-dodge.gif
[learning-to-see-paint]: ../assets/img/learning-to-see-paint.gif
[project-pupil-chemistry]: ../assets/img/project-pupil.gif
[super-hot]: ../assets/img/super-hot.gif
[leap-mirrorworlds-concept]: ../assets/img/mirrorworlds-concept.gif
[pokemon-go]:
[beat-saber]:
[alphago]:
[waymo]:
[pix-2-cats-1]:
[pix-2-cats-2]:
[pix-2-cats-derpy-cat]: ../assets/img/pix-to-cats-derpy-cat.PNG
[machine-eye-memo]:
[openpose]:
[everybody-dance-now]:
[intel-realsense-ml-vr]:


[Wilmington]: ../assets/img/wilmington-deep-dream.gif
[alina-north-star]: ../assets/img/alina-north-star.jpg
[north-star-build-summer-2018]: ../assets/img/north-star-build-summer-2018.jpg
[mirrorworlds-leap-illustration]: ../assets/img/mirrorworlds.gif
[reality-virtually-hci-squad]: ../assets/img/reality-virtually-2019-hci-squad.jpg
[escape-room]: ../assets/img/reality-virtually-2019-escape-room.gif


[project-pupil]: https://twitter.com/YujinAriza/status/1068619034827083783
[alphago]: https://www.alphagomovie.com/images/gallery/gallery-9.jpg
[Intel]: https://youtu.be/VSHDyUXSNqY?t=1069
[matrix]: https://youtu.be/xZ0OUq_kDh8?t=20
[super-hot]: https://www.youtube.com/watch?v=pzG7Wc6mbwE
[leap-light]: https://twitter.com/keiichiban/status/1034475041650630656
[mirror]: http://blog.leapmotion.com/mirrorworlds/
[painting]: https://vimeo.com/302624466
[corning]: youtu.be/jZkHpNnXLB0

“What is the Next Generation of Human-Computer Interaction?” CHI 2006 Workshop Proceedings, cs.tufts.edu/~jacob/workshop/report.pdf.
“Entering the Metaverse.” Liv Erickson, livi.link/entering-metaverse-pdf.
http://photoblog.nbcnews.com/_news/2013/03/14/17312316-witnessing-papal-history-changes-with-digital-age
https://courses.lumenlearning.com/boundless-chemistry/chapter/molecular-geometry/

Works Cited

Ariza, Yujin. “More Players? Why Not Pic.twitter.com/WcrF5w30hV.” Twitter, Twitter, 30 Nov. 2018, twitter.com/YujinAriza/status/1068619034827083783.
“Deep Learning for VR/AR: Body Tracking.” Intel RealSense, realsense.intel.com/deep-learning-for-vr-ar/.
“Deep Learning for VR/AR: Body Tracking with Intel RealSense Technology.” YouTube, YouTube, 29 Nov. 2018, youtu.be/VSHDyUXSNqY.
“DensePose.” DensePose, densepose.org/.
“The End of Cloud Computing.” YouTube, YouTube, 15 July 2017, youtu.be/4QTAtFaIiyc.
“Fei-Fei Li on AI and Machine Learning.” YouTube, YouTube, 5 Feb. 2018, youtu.be/XlnbNFW2tX8.
“Google Developer Day at GDC 2018 Livestream.” YouTube, YouTube, 19 Mar. 2018, youtu.be/5wtlj_q3DjE.
Kipman, Alex. “A Futuristic Vision of the Age of Holograms.” Ted, Ted, www.ted.com/talks/alex_kipman_the_dawn_of_the_age_of_holograms.
“Learning to See: Gloomy Sunday.” Vimeo, 12 Jan. 2019, vimeo.com/260612034.
“Learning to See: We Are Made of Star Dust (#2).” Vimeo, 12 Jan. 2019, vimeo.com/242498070.
Li, Fei-Fei. “How We're Teaching Computers to Understand Pictures.” Ted, Ted, www.ted.com/talks/fei_fei_li_how_we_re_teaching_computers_to_understand_pictures.
Matsuda, Keiichi. “HYPER-REALITY.” YouTube, YouTube, 19 May 2016, www.youtube.com/watch?v=YJg02ivYzSs.
Matsuda, Keiichi. “Using #ProjectNorthStar to Tap Back in to Physical Reality. Lots of Possibilities Spring from Combining #AR with #IoT. @Tweethue Pic.twitter.com/triANhovp7.” Twitter, Twitter, 28 Aug. 2018, twitter.com/keiichiban/status/1034475041650630656.
Matsuda, Keiichi. “Using #ProjectNorthStar to Tap Back in to Physical Reality. Lots of Possibilities Spring from Combining #AR with #IoT. @Tweethue Pic.twitter.com/triANhovp7.” Twitter, Twitter, 28 Aug. 2018, twitter.com/keiichiban/status/1034475041650630656.
“Maureen Fan Explains the Power of VR and Animation.” YouTube, YouTube, 5 Feb. 2018, youtu.be/1xVyQhthH3s.
Motion, Leap. “‘It's Weird That a Child with a Piece of Clay Has More Power than a Professional with a Computer." This Week, Leap Motion Was Featured in the @WSJ as Part of a Larger Conversation around Interfaces of the Future. Https://T.co/DCde8I0MwI.” Twitter, Twitter, 4 Oct. 2018, twitter.com/LeapMotion/status/1047833574689452034.
“The Next Leap: How A.I. Will Change the 3D Industry - Andrew Price.” YouTube, YouTube, 5 Nov. 2018, youtu.be/FlgLxSLsYWQ.
“Origami: ReImagining Reality.” Procedural Worlds, 21 Mar. 2018, www.procedural-worlds.com/blog/origami-reimagining-reality/.
SUPERHOT. “SUPERHOT VR Release Trailer.” YouTube, YouTube, 5 Dec. 2016, www.youtube.com/watch?v=pzG7Wc6mbwE.
“Summoning and Superpowers: Designing VR Interactions at a Distance.” Leap Motion Blog, 25 Jan. 2018, blog.leapmotion.com/summoning-superpowers-designing-vr-interactions-distance/.
